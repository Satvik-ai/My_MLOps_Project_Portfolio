MLOps Project Portfolio

Welcome to my portfolio of **Machine Learning Operations (MLOps)** projects.
This collection showcases my hands-on experience in designing, building, and deploying end-to-end machine learning systems across different stages of the ML lifecycle.

The projects demonstrate practical expertise in areas such as data and model versioning, feature management, experiment tracking, CI/CD automation, scalable deployment on Kubernetes, monitoring, and Responsible AI practices including fairness and explainability.

Together, they reflect my approach to building reproducible, scalable, and production-ready ML systems using modern MLOps tools and cloud platforms.

---

| ðŸš€ Project | ðŸ“„ Description |
------------- | -------------
[Heart Disease ML Model â€” End-to-End MLOps with CI/CD, Monitoring & Governance](https://github.com/Satvik-ai/21F1000344_IITMBS_MLOPS_OPPE2) | This project demonstrates a production-grade MLOps pipeline for a Heart Disease prediction model. It covers the full lifecycle â€” from data versioning and training to deployment on Kubernetes, monitoring, fairness analysis, and explainability.The pipeline is designed to simulate a real-world ML system with automated testing, deployment, stress testing, and model governance.
[Gemma2 Finetuning using IRIS Data](https://github.com/Satvik-ai/mlops-assignment-10) | This project demonstrates how a Large Language Model (LLM) can be adapted for a traditional classification task by finetuning Gemma2-2B-IT on the IRIS dataset using Vertex AI. 
[Iris Detection with Governance](https://github.com/Satvik-ai/mlops-assignment-9) | This project demonstrates how AI governance techniques can be applied to a classic machine learning task using the IRIS dataset. It introduces a synthetic sensitive attribute (location), evaluates fairness using Fairlearn, and explains model behavior using SHAP and Evidently. The goal is to show how model performance, fairness, and interpretability can be assessed together in a practical workflow.
[Iris Classification ML Model â€” Data Poisoning Effect](https://github.com/Satvik-ai/mlops-assignment-8) | This project explores how data poisoning impacts the performance of a machine learning model trained on the classic IRIS dataset. Different levels of synthetic noise (5%, 10%, and 50%) are introduced into the dataset to simulate corrupted or malicious data, and the resulting changes in validation performance are tracked using MLflow. The project demonstrates the importance of data quality, experiment tracking, and reproducibility in ML pipelines.
[Iris Classification ML Model â€” CI/CD Pipeline with Stress Testing & Kubernetes Autoscaling](https://github.com/Satvik-ai/mlops-assignment-7) | This project extends the Iris ML CI/CD pipeline to evaluate deployment robustness under high load. It demonstrates how to stress test a production ML API, observe system behavior, and validate Kubernetes Horizontal Pod Autoscaling (HPA). The pipeline automates testing scenarios using wrk, enabling performance benchmarking and bottleneck analysis.
[Iris Classification ML Model â€” CI/CD Pipeline with FastAPI & Kubernetes](https://github.com/Satvik-ai/mlops-assignment-6) | This project demonstrates a production-ready machine learning deployment pipeline that automates: Model training and validation, Continuous Integration (CI), Containerization with Docker and Continuous Deployment (CD) to Kubernetes. The pipeline builds an Iris classification API using FastAPI, packages it into a Docker image, pushes it to Google Artifact Registry, and deploys it to Google Kubernetes Engine (GKE) using GitHub Actions.
[Iris Classification ML Project with DVC, MLflow, and Feast](https://github.com/Satvik-ai/mlops-assignment-5) | This project demonstrates a production-grade machine learning pipeline that integrates: DVC for data versioning, MLflow for experiment tracking and model registry and Feast for feature management and serving. The repository showcases how modern ML systems manage data, features, experiments, and models in a reproducible and scalable workflow.
[Iris Classification ML Project with DVC Tracking and CI (GitHub Actions)](https://github.com/Satvik-ai/mlops-assignment-4) | This project demonstrates a production-style machine learning workflow that combines: Data & model versioning with DVC, Automated testing with pytest, Continuous Integration using GitHub Actions, and Experiment reproducibility with CML reports. The repository simulates a real-world ML development lifecycle with branch-based CI, automated validation, and reproducible pipelines.
[Iris Classification ML Project with Feast Feature Store](https://github.com/Satvik-ai/mlops-assignment-3) | This project demonstrates how to integrate a Feature Store (Feast) into a machine learning pipeline for Iris flower classification. It showcases how to define, store, retrieve, and serve features consistently during both training and inference, ensuring reproducibility and eliminating trainingâ€“serving skew. The project uses Google Cloud Storage (GCS) as the data source and backend storage.
[Iris Classification ML Project with DVC Tracking](https://github.com/Satvik-ai/mlops-assignment-2) | This project demonstrates an end-to-end machine learning workflow with data and model versioning using DVC (Data Version Control). It showcases how to track dataset changes, reproduce experiments, and manage model artifacts while using Google Cloud Storage (GCS) as remote storage. The repository highlights best practices for ML experiment tracking, reproducibility, and version control.
[Iris Classification ML Project (Vertex AI)](https://github.com/Satvik-ai/mlops-assignment-1) | This project implements an end-to-end machine learning pipeline for classifying Iris flower species using Google Cloud Platform (GCP) Vertex AI. It demonstrates the full lifecycle of an ML model â€” from data retrieval and training to deployment and inference. The repository is designed to showcase practical experience with cloud-based ML workflows, reproducible pipelines, and model serving.

---

## ðŸ“« Contact

Feel free to connect with me for collaborations, feedback, or opportunities.

- ðŸ”— [LinkedIn](https://www.linkedin.com/in/satvik-chandrakar-4008471ba)
- ðŸ“§ [Email](mailto:chandrakarsatvik@gmail.com)

---

_Thank you for visiting my portfolio!_
